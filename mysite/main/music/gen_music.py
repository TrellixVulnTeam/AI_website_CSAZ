import pickle #To save and retrieve weights
import tensorflow as tf #Deep learning library
import numpy as np#for Math
from music21 import instrument, chord, note, stream #to handle music files i.e save convert read etc
from keras.models import Sequential #to create a model
from keras.layers import Dense, Dropout, LSTM, Activation # to create and add these layers to model

def gen():
	''' function to generate music'''
	#loading the notes files created while training
	with open('data/notes', 'rb') as f: #opening the file as variable f
		notes = pickle.load(f) #Getting the notes in notes variable

	pitch_names = sorted(set(item for item in notes)) #sorting all the notes 
	n = len(set(notes)) #getting the total number of individual notes

	inp, norm_inp = normalize(notes, pitch_names, n) #getting input in categorical format and also the normalized input 	

	model = make_model(norm_inp,n) #Getting the model from the funcion
	pred = gen_notes(model,inp,pitch_names,n)
	make_midi(pred)

def normalize(notes,pitch_names,n):
	#prepare the data for neural network
	#Also map the inputs to intigers to use in the network

	note_int = dict((note, number) for number, note in enumerate(pitch_names)) #Mapping numbers to notes and storing in the variabel

	l = 100 #min number of inuts req to make predictions
	inp = [] #to collect the input in integer form
	
	for i in range(0,len(notes) - l): #looping through all notes
		sequence_inp = notes[i:i+l] #taking the notes from i to i+l i.e 100 + i. to get the next notes
		seq_out = notes[i+l]  
		inp.append([note_int[x] for x in sequence_inp]) #getting the categorical number of hte note from note_int

	n_patterns = len(inp) #number of patterns
	
	norm_inp = np.reshape(inp, (n_patterns, l, 1)) #Reshaping the array to a tensor so that we can feed it in our network
	norm_inp = norm_inp / float(n) #normalizing the input 

	return (inp,norm_inp)
		
def make_model(inp,n):

	model = Sequential() #making object of sequential class
	model.add(LSTM(512, input_shape = (inp.shape[1], inp.shape[2]),return_sequences = True)) #adding a LSTM network and filling in the required parameters 
	model.add(Dropout(0.3)) #Addng dropout layer, regularization
	model.add(LSTM(512,return_sequences = True))
	model.add(Dropout(0.3))
	model.add(LSTM(512))
	model.add(Dense(256)) #basic deep neural network
	model.add(Dropout(0.3))
	model.add(Dense(n))
	model.add(Activation('softmax')) #to get the number of outputs same as number of individual notes
	model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop') #loss function for back-propogation

	model.load_weights('weights.hdf5') #loading the pre-trained weights to generate music

	return model

def gen_notes(model,inp,pitch_names,n):
	#pick a random seq from inp to start generation
	first = np.random.randint(0,len(inp) - 1)
	int_note = dict((number, note) for number, note in enumerate(pitch_names)) #getting the notes from number to convert the categorial integers back into notes

	start = inp[first] #get the first categorical note
	pred = [] #to store all the predictions

	for index in range(500): #to generate next 500 notes
		pred_inp = np.reshape(start,(1,len(start),1)) #changing into tensor
		pred_inp = pred_inp / float(n) #normalizing

		prediction = model.predict(pred_inp,verbose = 0) #to not display anything in console while  predcting next note from input

		most_likely = np.argmax(prediction) #get the max of all outputs
		res = int_note[most_likely] #get the note for the categorical variable
		pred.append(res) #adding the reslt to the final array of predictions

		start.append(most_likely) #adding the pred to start to continue the loop
		start = start[1:len(start)]  

	return pred	

def make_midi(prediction_output):
    """ convert the output from the prediction to notes and create a midi file
        from the notes """
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 0.5

    midi_stream = stream.Stream(output_notes)

    midi_stream.write('midi', fp='test_output.mid')


if __name__ == '__main__':
	gen()














